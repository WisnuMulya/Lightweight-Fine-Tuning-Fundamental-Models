{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042f4235-b8c3-44e0-b51e-5d9e72dbb677",
   "metadata": {},
   "source": [
    "# Parameter-Efficient Fine-Tuning on GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95796888-0a72-4302-b7c9-d1b76b2320f4",
   "metadata": {},
   "source": [
    "## 1. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7a62dd-f9bf-4869-a218-b2842b8daca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981cf89e-7670-4bd1-8e9a-ed3c3b6b55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "dataset = load_dataset(\"AdaptLLM/medicine-tasks\", \"PubMedQA\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafcb168-445e-4aaf-ab2b-01593a705082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'id', 'gold_index', 'options'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cd2af0-5ba8-4d2e-9264-6a4321493820",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=.2, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea714219-4123-4f09-8d42-ca09d1f61998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'id', 'gold_index', 'options'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'id', 'gold_index', 'options'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061db2b5-98c7-45c5-997f-bbe74b1b216f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Context: (Background and objective) Optimization of the preoperative hemoglobin (Hb) level is an effective way to reduce allogeneic transfusion in total knee arthroplasty (TKA) though the procedure is expensive, requires close monitoring and is often inconvenient for patients with reduced mobility. Our aim was to investigate the value of preoperative Hb levels to predict transfusion and thereby tailoring Hb optimization to patient characteristics.\\n(Materials and methods) All consecutive patients who undergone primary TKA in our center over 2\\xa0years, and received tranexamic acid intraoperatively, were reviewed. The adjusted association between preoperative Hb levels and transfusion was assessed by multivariate logistic regression, and the estimated probability of transfusion for individual patients was derived from the logistic model.\\n(Results) Out of the 784 patients who meet the inclusion criteria, risk of transfusion was associated with poorer performance status, as measured by the America Association of Anestesiology (ASA) score III/IV (OR: 3·3, P\\xa0<\\xa00·001) and lower preoperative Hb level (OR 3·8 for each g/dl below 13\\xa0g/dl; P\\xa0<\\xa00·001). According to the Hb level, the estimated probability of transfusion was 0·03 (range: 0·03-0·64) for ASA I/II patients and 0·10 (range: 0·10-0·84) for ASA III/IV.\\nQuestion: Should all patients be optimized to the same preoperative hemoglobin level to avoid transfusion in primary knee arthroplasty?\\nAnswer:',\n",
       " 'id': 911,\n",
       " 'gold_index': 0,\n",
       " 'options': ['No', 'Maybe', 'Yes']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data point\n",
    "split_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b968f9c-426c-493f-b1e2-6dc0dfeb76d3",
   "metadata": {},
   "source": [
    "### 1.1. Dataset Interpretation\n",
    "The dataset contains 1,000 data points containing questions (`input`) prefixed by some biomedical context and their answers (`gold_index`) of \"no\", \"maybe\", or \"yes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c8b52-0eec-4336-9a89-bf5475f04037",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a135d3-6d1f-469d-813e-5130699c4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d86559a-7550-459e-b073-d0a3eabccbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86246a6a-fd8f-4799-abfa-42d2c511b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix issue of inexistent pad_token \n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0937ed06-cbc7-43e7-831b-f3d79065244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dict()\n",
    "\n",
    "def preprocess_fn(data):\n",
    "    del data['options']\n",
    "    del data['id']\n",
    "    data['labels'] = data['gold_index']\n",
    "    del data['gold_index']\n",
    "\n",
    "    return tokenizer(data[\"input\"], padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    tokenized_dataset[split] = split_dataset[split].map(preprocess_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5561fa36-9b62-4713-8ec8-3fc00db3585a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': Dataset({\n",
      "    features: ['input', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 200\n",
      "}),\n",
      " 'train': Dataset({\n",
      "    features: ['input', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 800\n",
      "})}\n",
      "{'input': 'Context: (Background and objective) Optimization of the preoperative hemoglobin (Hb) level is an effective way to reduce allogeneic transfusion in total knee arthroplasty (TKA) though the procedure is expensive, requires close monitoring and is often inconvenient for patients with reduced mobility. Our aim was to investigate the value of preoperative Hb levels to predict transfusion and thereby tailoring Hb optimization to patient characteristics.\\n(Materials and methods) All consecutive patients who undergone primary TKA in our center over 2\\xa0years, and received tranexamic acid intraoperatively, were reviewed. The adjusted association between preoperative Hb levels and transfusion was assessed by multivariate logistic regression, and the estimated probability of transfusion for individual patients was derived from the logistic model.\\n(Results) Out of the 784 patients who meet the inclusion criteria, risk of transfusion was associated with poorer performance status, as measured by the America Association of Anestesiology (ASA) score III/IV (OR: 3·3, P\\xa0<\\xa00·001) and lower preoperative Hb level (OR 3·8 for each g/dl below 13\\xa0g/dl; P\\xa0<\\xa00·001). According to the Hb level, the estimated probability of transfusion was 0·03 (range: 0·03-0·64) for ASA I/II patients and 0·10 (range: 0·10-0·84) for ASA III/IV.\\nQuestion: Should all patients be optimized to the same preoperative hemoglobin level to avoid transfusion in primary knee arthroplasty?\\nAnswer:', 'labels': 0, 'input_ids': [21947, 25, 357, 21756, 290, 9432, 8, 30011, 1634, 286, 262, 662, 27173, 16869, 49835, 357, 39, 65, 8, 1241, 318, 281, 4050, 835, 284, 4646, 477, 20878, 291, 13501, 4241, 287, 2472, 10329, 610, 26110, 489, 7833, 357, 51, 25123, 8, 996, 262, 8771, 318, 5789, 11, 4433, 1969, 9904, 290, 318, 1690, 37513, 329, 3871, 351, 5322, 15873, 13, 3954, 4031, 373, 284, 9161, 262, 1988, 286, 662, 27173, 367, 65, 2974, 284, 4331, 13501, 4241, 290, 12839, 7894, 3255, 367, 65, 23989, 284, 5827, 9695, 13, 198, 7, 41657, 290, 5050, 8, 1439, 12785, 3871, 508, 29900, 4165, 309, 25123, 287, 674, 3641, 625, 362, 1849, 19002, 11, 290, 2722, 491, 272, 1069, 18127, 7408, 23422, 3575, 9404, 11, 547, 11765, 13, 383, 12328, 8112, 1022, 662, 27173, 367, 65, 2974, 290, 13501, 4241, 373, 15276, 416, 1963, 42524, 2604, 2569, 20683, 11, 290, 262, 6108, 12867, 286, 13501, 4241, 329, 1981, 3871, 373, 10944, 422, 262, 2604, 2569, 2746, 13, 198, 7, 25468, 8, 3806, 286, 262, 767, 5705, 3871, 508, 1826, 262, 14900, 9987, 11, 2526, 286, 13501, 4241, 373, 3917, 351, 26647, 2854, 3722, 11, 355, 8630, 416, 262, 2253, 5396, 286, 1052, 395, 274, 12371, 357, 1921, 32, 8, 4776, 6711, 14, 3824, 357, 1581, 25, 513, 9129, 18, 11, 350, 1849, 27, 1849, 15, 9129, 8298, 8, 290, 2793, 662, 27173, 367, 65, 1241, 357, 1581, 513, 9129, 23, 329, 1123, 308, 14, 25404, 2174, 1511, 1849, 70, 14, 25404, 26, 350, 1849, 27, 1849, 15, 9129, 8298, 737, 4784, 284, 262, 367, 65, 1241, 11, 262, 6108, 12867, 286, 13501, 4241, 373, 657, 9129, 3070, 357, 9521, 25, 657, 9129, 3070, 12, 15, 9129, 2414, 8, 329, 49599, 314, 14, 3978, 3871, 290, 657, 9129, 940, 357, 9521, 25, 657, 9129, 940, 12, 15, 9129, 5705, 8, 329, 49599, 6711, 14, 3824, 13, 198, 24361, 25, 10358, 477, 3871, 307, 23392, 284, 262, 976, 662, 27173, 16869, 49835, 1241, 284, 3368, 13501, 4241, 287, 4165, 10329, 610, 26110, 489, 7833, 30, 198, 33706, 25, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect pre-processed dataset\n",
    "pprint(tokenized_dataset)\n",
    "print(tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77a367a-d4fe-4736-a3a4-60aed02358ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828ee49-1783-4cd9-8b14-33585d7cd7a5",
   "metadata": {},
   "source": [
    "## 2. Loading and Evaluating a Pre-Trained GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d2a5c7b-d966-4043-9633-927b14266d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from transformers import GPT2ForSequenceClassification, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55210f85-7b6e-49c8-b4df-b89215a7bf66",
   "metadata": {},
   "source": [
    "### 2.1. Loading GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8dc59c-46eb-40f2-aa2c-45470ffa68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=3,\n",
    "    id2label={0: \"No\", 1: \"Maybe\", 2: \"Yes\"},\n",
    "    label2id={\"No\": 0, \"Maybe\": 1, \"Yes\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc325f2-2cf5-46fe-8485-6363be7a2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf6e8d-0122-4561-b3f5-96ed35a7b661",
   "metadata": {},
   "source": [
    "### 2.2. Freeze All Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b078a9-8464-47e9-9333-9bd6cc74073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b55551-15c4-4d71-ade0-d813b19ebb41",
   "metadata": {},
   "source": [
    "### 2.3. Train Classifier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c265b88a-5758-4ee7-8201-3026fa3e0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bc6c9a-1737-4315-bdb6-4520c1b473e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a4060ed-8558-4489-b7f5-e0f46074b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix issue of inexistent pad_token \n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a6a8468-0a59-4f0a-acb5-c160518a104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 08:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.127955</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.079048</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.025596</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.151500</td>\n",
       "      <td>1.025908</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=640, training_loss=1.121945571899414, metrics={'train_runtime': 531.0356, 'train_samples_per_second': 6.026, 'train_steps_per_second': 1.205, 'total_flos': 1672314303283200.0, 'train_loss': 1.121945571899414, 'epoch': 4.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier layer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/biomedical_question\",\n",
    "        learning_rate=2e-4,\n",
    "        per_device_train_batch_size=5,\n",
    "        per_device_eval_batch_size=5,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer, padding=\"max_length\"),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121f266-1362-4757-a555-7b236169b8bb",
   "metadata": {},
   "source": [
    "### 2.4. Evaluate Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248e7396-bbe6-4b3c-816e-21fe0dfda96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0255961418151855,\n",
       " 'eval_accuracy': 0.45,\n",
       " 'eval_runtime': 21.2508,\n",
       " 'eval_samples_per_second': 9.411,\n",
       " 'eval_steps_per_second': 1.882,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aca1b0-efbc-41bd-a2d0-ff99435cc980",
   "metadata": {},
   "source": [
    "## 3. Performing Parameter-Efficient Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf5c6c-c2e5-483e-a023-38abc7098b9c",
   "metadata": {},
   "source": [
    "### 3.1. Creating Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a2b58-328f-485d-999e-9f7708555d37",
   "metadata": {},
   "source": [
    "#### 3.1.1. Lora Config 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb2baee8-7af0-48c1-a12b-debbc14ed381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a3dd8f1-eecd-4a90-b5a9-72402ed4af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_1 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32.0,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_proj\"],\n",
    "    modules_to_save=[\"score\"],\n",
    "    task_type=TaskType.TOKEN_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef9ce1-cfd3-4efb-80d0-8a2bd6eb1c93",
   "metadata": {},
   "source": [
    "#### 3.1.2. Lora Config 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0babb6a8-8bc1-48ad-a5e4-e7196b783c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_2 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32.0,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_proj\"],\n",
    "    modules_to_save=[\"score\"],\n",
    "    task_type=TaskType.TOKEN_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd040630-a606-4c60-982d-bd89741cc50a",
   "metadata": {},
   "source": [
    "### 3.2. Converting Transformers to PEFT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4990d7-d699-4fd4-9ce2-6747f9d106a4",
   "metadata": {},
   "source": [
    "#### 3.2.1. Lora 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a981d715-ef35-4f3b-9af3-8b79ec224730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_1 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=3,\n",
    "    id2label={0: \"No\", 1: \"Maybe\", 2: \"Yes\"},\n",
    "    label2id={\"No\": 0, \"Maybe\": 1, \"Yes\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d2367c8-6906-4568-bc13-f4df8947d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89564ada-b04b-4f06-b375-a4173727c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/peft/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/peft/lib/python3.12/site-packages/peft/tuners/lora/layer.py:711: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_lora_1 = get_peft_model(model_1, config_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffef471a-8fdd-42cb-808f-3257378cb27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,034,496 || all params: 125,476,608 || trainable%: 0.8244532718002705\n"
     ]
    }
   ],
   "source": [
    "model_lora_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534a4ad-598c-4831-9163-3b3534d1ef48",
   "metadata": {},
   "source": [
    "#### 3.2.2. Lora 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0fca2d7-d2ee-40e2-aa24-b18165b14057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=3,\n",
    "    id2label={0: \"No\", 1: \"Maybe\", 2: \"Yes\"},\n",
    "    label2id={\"No\": 0, \"Maybe\": 1, \"Yes\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d32f590-07fa-4f8d-b6a6-67ca86a44511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac803ca-a683-4795-a7d3-b9ef04354cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora_2 = get_peft_model(model_2, config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8d9a2e4-fc3c-4788-80f5-58bca5337243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 518,400 || all params: 124,960,512 || trainable%: 0.41485105310708076\n"
     ]
    }
   ],
   "source": [
    "model_lora_2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff0622-e18c-4144-92ee-bd1955ce8aeb",
   "metadata": {},
   "source": [
    "### 3.3. Training with PEFT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a965184-6074-4405-8929-c43847dd8169",
   "metadata": {},
   "source": [
    "#### 3.3.1. Training Lora 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1987aebe-5032-4106-93f3-dd6857a237d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 27:30, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.138670</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.092006</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002002</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.050500</td>\n",
       "      <td>0.986839</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=536, training_loss=1.0442770844075218, metrics={'train_runtime': 1652.9833, 'train_samples_per_second': 1.936, 'train_steps_per_second': 0.324, 'total_flos': 1692653322240000.0, 'train_loss': 1.0442770844075218, 'epoch': 4.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora_1 = Trainer(\n",
    "    model=model_lora_1,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/biomedical_question_lora_1\",\n",
    "        learning_rate=2e-4,\n",
    "        per_device_train_batch_size=6,\n",
    "        per_device_eval_batch_size=6,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer, padding=\"max_length\"),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_lora_1.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0706c66-16bb-470f-825b-f748b61508dc",
   "metadata": {},
   "source": [
    "#### 3.3.2. Training Lora 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4211062-536f-4ea0-9190-ea9d51091513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 29:55, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.047271</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.980976</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.964919</td>\n",
       "      <td>0.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>0.957475</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=536, training_loss=0.9684191746498222, metrics={'train_runtime': 1799.5746, 'train_samples_per_second': 1.778, 'train_steps_per_second': 0.298, 'total_flos': 1682506462003200.0, 'train_loss': 0.9684191746498222, 'epoch': 4.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier layer\n",
    "trainer_lora_2 = Trainer(\n",
    "    model=model_lora_2,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/biomedical_question_lora_2\",\n",
    "        learning_rate=2e-4,\n",
    "        per_device_train_batch_size=6,\n",
    "        per_device_eval_batch_size=6,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer, padding=\"max_length\"),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_lora_2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08241c8d-8822-4046-bf09-8846d9d3c3d5",
   "metadata": {},
   "source": [
    "### 3.4. Save the PEFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f200352d-05de-4b7a-9848-f149c64e23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora_1.save_pretrained('gpt_lora_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b58888b5-696e-421a-af4b-22f8874a78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora_2.save_pretrained('gpt_lora_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830bc55-8192-4e00-92bc-987617742017",
   "metadata": {},
   "source": [
    "## 4. Perform Inference with PEFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367dd2e-cce1-41b9-9ac4-cb033307bcac",
   "metadata": {},
   "source": [
    "### 4.1. Load Saved PEFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fe94381-1b46-4930-8930-395aeeb3c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification, AutoPeftModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5cda885-376e-4080-b6ba-0204a596f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpt_lora_1 = AutoPeftModelForTokenClassification.from_pretrained(\n",
    "    'gpt_lora_1',\n",
    "    num_labels=3,\n",
    "    id2label={0: \"No\", 1: \"Maybe\", 2: \"Yes\"},\n",
    "    label2id={\"No\": 0, \"Maybe\": 1, \"Yes\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d9489ec-25b1-4c01-961c-9ac698881b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpt_lora_2 = AutoPeftModelForTokenClassification.from_pretrained(\n",
    "    'gpt_lora_2',\n",
    "    num_labels=3,\n",
    "    id2label={0: \"No\", 1: \"Maybe\", 2: \"Yes\"},\n",
    "    label2id={\"No\": 0, \"Maybe\": 1, \"Yes\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff340cfa-0dcb-44bc-8bf0-d161c4529ceb",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate PEFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38a25331-a7f1-41ad-9081-ce81334b0fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9868389964103699,\n",
       " 'eval_accuracy': 0.53,\n",
       " 'eval_runtime': 23.4249,\n",
       " 'eval_samples_per_second': 8.538,\n",
       " 'eval_steps_per_second': 1.451,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01bdd3a6-fec7-41de-a0fc-ceb760464ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9574746489524841,\n",
       " 'eval_accuracy': 0.505,\n",
       " 'eval_runtime': 24.0212,\n",
       " 'eval_samples_per_second': 8.326,\n",
       " 'eval_steps_per_second': 1.415,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora_2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63441fb4-a2b1-4906-afc8-8cdb9cbc1e6f",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19922714-a96e-416f-82b6-303a4b380674",
   "metadata": {},
   "source": [
    "Based on the evaluation of the PEFT models, the better one is the model with the first configuration:\n",
    "```\n",
    "config_1 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32.0,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_proj\"],\n",
    "    modules_to_save=[\"score\"],\n",
    "    task_type=TaskType.TOKEN_CLS\n",
    ")\n",
    "```\n",
    "The accuracy of the above model is .53, which is an increase from the .45, where the model's parameter were being freezed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
